{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fccfec5-15bd-40f9-8c8b-8d66e37c4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07651e74-a1f8-4e51-9397-7767794491aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv', index_col=0).sort_index()\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0).sort_index()\n",
    "X_test = pd.read_csv('X_test.csv', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76016cfe-7129-4f6f-82e8-240388e0652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals : 1172086.\n",
      "Pour l'année 2022, il y a 412647 individus.\n",
      "Pour l'année 2018, il y a 411320 individus.\n",
      "Pour l'année 2015, il y a 348119 individus.\n",
      "Total number of individuals in test: 586044.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of individuals : {len(X_train)}.\")\n",
    "years = X_train['Year'].unique()\n",
    "for year in years:\n",
    "  count_year = len(X_train[X_train['Year']==year])\n",
    "  print(f\"Pour l'année {year}, il y a {count_year} individus.\")\n",
    "\n",
    "print(f\"Total number of individuals in test: {len(X_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195953d2-3256-4928-8b05-7fb76b572a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1954f7c-ba64-459a-995f-4c897163a7cb",
   "metadata": {},
   "source": [
    "# Choosing which columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a49c83-aebb-4672-981d-04a08d581f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6800af-bfb4-4404-8fc0-0ac51b6dc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_null = X_train.isna().sum()\n",
    "kept_cols = list(count_null[count_null < 0.5 * len(X_train)].index)\n",
    "\n",
    "exclude_substrings = ['_total_timing', '_average_score', 'CNTRYID', 'CNTSTUID', 'BOOKID']\n",
    "\n",
    "final_cols = [col for col in kept_cols if not any(substr in col for substr in exclude_substrings)]\n",
    "\n",
    "X_train = X_train[final_cols]\n",
    "X_test = X_test[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e0601-2a4b-4dd6-bff9-3b23ee25e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The different types of columns \n",
    "categorical1 = ['Year', 'CNT', 'CYC', 'STRATUM', 'OECD', 'ADMINMODE', 'ST004D01T', 'IMMIG', 'CNTSCHID']\n",
    "categorical_cols = []\n",
    "binary_cols = []\n",
    "numeric_cols = []\n",
    "categorical_threshold = 5\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if len(set(X_train[col].dropna().unique()))==2:\n",
    "        binary_cols.append(col)\n",
    "    elif col in categorical1:\n",
    "        categorical_cols.append(col)\n",
    "    elif X_train[col].dtype == 'object':\n",
    "        categorical_cols.append(col)\n",
    "    elif pd.api.types.is_numeric_dtype(X_train[col]):\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Binary columns (0/1): {len(binary_cols)}\")\n",
    "print(f\"Real/numeric columns: {len(numeric_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ac6ae-da35-4e0c-8f10-f3c93e6b9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    print(f\"For {col}: {len(X_train[col].unique())} unique values and {len(X_train[X_train[col].isna()])} missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d8bdc0-3126-4d83-bb47-be732e3eb331",
   "metadata": {},
   "source": [
    "# Imputing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c50f4-cb52-427b-a978-bfbe99049d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c82c1-99fb-4751-b8ef-c25c416f345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X_train[numeric_cols] = imputer_num.fit_transform(X_train[numeric_cols])  # fit on train\n",
    "X_test[numeric_cols] = imputer_num.transform(X_test[numeric_cols])\n",
    "\n",
    "# Categorical or binary columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train[binary_cols] = imputer_cat.fit_transform(X_train[binary_cols])\n",
    "X_test[binary_cols] = imputer_cat.transform(X_test[binary_cols])\n",
    "\n",
    "X_train[categorical_cols] = imputer_cat.fit_transform(X_train[categorical_cols])\n",
    "X_test[categorical_cols] = imputer_cat.transform(X_test[categorical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2c788-cb49-46cb-a051-72863a17f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbafcd-fdd4-4ded-91d1-1699d670037b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd25938-0186-40b1-9bbb-6f1c8d4c94a7",
   "metadata": {},
   "source": [
    "# Scaling and One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619a500-38e3-4af9-a8d3-ceef4f904023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of the numerical variable \n",
    "do_standard_scaler = True \n",
    "\n",
    "if do_standard_scaler:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[numeric_cols])\n",
    "    X_train_final = scaler.transform(X_train[numeric_cols])\n",
    "    X_train_final = pd.DataFrame(X_train_final, columns=numeric_cols, index=X_train.index)\n",
    "\n",
    "    X_test_final = scaler.transform(X_test[numeric_cols])\n",
    "    X_test_final = pd.DataFrame(X_test_final, columns=numeric_cols, index=X_test.index)\n",
    "else:\n",
    "    X_train_final = X_train[numeric_cols].copy()\n",
    "    X_test_final = X_test[numeric_cols].copy()\n",
    "\n",
    "# One hot encoding of the binary\n",
    "for cat_variable in binary_cols:\n",
    "    dummies = pd.get_dummies(X_train[cat_variable], prefix=cat_variable)\n",
    "    X_train_final = pd.concat([X_train_final, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(X_test[cat_variable], prefix=cat_variable)\n",
    "    for col in [c for c in X_train_final.columns if c.startswith(cat_variable)]:\n",
    "        if col not in dummies.columns:\n",
    "            dummies[col] = 0\n",
    "    # Ensure same column order as training set\n",
    "    dummies = dummies[[c for c in X_train_final.columns if c.startswith(cat_variable)]]\n",
    "    X_test_final = pd.concat([X_test_final, dummies], axis=1)\n",
    "\n",
    "#One hot encoding of some of the categorical\n",
    "for cat_variable in ['Year', 'CNT', 'CYC', 'OECD', 'IMMIG']:\n",
    "    dummies = pd.get_dummies(X_train[cat_variable], prefix=cat_variable)\n",
    "    X_train_final = pd.concat([X_train_final, dummies], axis=1)\n",
    "    if cat_variable in X_train_final.columns:\n",
    "        X_train_final = X_train_final.drop(columns=[cat_variable])\n",
    "\n",
    "    dummies = pd.get_dummies(X_test[cat_variable], prefix=cat_variable)\n",
    "    # Add any missing columns from training set with 0s\n",
    "    for col in [c for c in X_train_final.columns if c.startswith(cat_variable)]:\n",
    "        if col not in dummies.columns:\n",
    "            dummies[col] = 0\n",
    "    # Ensure same column order as training set\n",
    "    dummies = dummies[[c for c in X_train_final.columns if c.startswith(cat_variable)]]\n",
    "    X_test_final = pd.concat([X_test_final, dummies], axis=1)\n",
    "\n",
    "X_test = X_test_final.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a8c58-97e3-4ba4-856a-fa2dbcd549bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_test_final, y_train, y_test = train_test_split(X_train_final, y_train, test_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfe65a-ff62-4bbf-9e3b-f1e9b676b7a8",
   "metadata": {},
   "source": [
    "# Remove the highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5562c-3a72-413f-a891-828f4f5c163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train_final.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "high_corr = corr_matrix.where(mask).stack().sort_values(ascending=False)\n",
    "high_corr = high_corr[high_corr > 0.9]\n",
    "\n",
    "to_drop = set()\n",
    "for f1, f2 in high_corr.index:\n",
    "    if f2 not in to_drop:\n",
    "        to_drop.add(f2)\n",
    "\n",
    "print(f\"Dropping {len(to_drop)} variables.\")\n",
    "\n",
    "X_train_final = X_train_final.drop(columns=list(to_drop))\n",
    "X_test_final = X_test_final.drop(columns=list(to_drop))\n",
    "X_test = X_test.drop(columns=list(to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19598d-5081-43ba-8dab-9a7d01d71006",
   "metadata": {},
   "source": [
    "## Regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e27047e-e0b0-4593-adb9-50208456b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.01),\n",
    "    \"Gradient Boosting 1\": XGBRegressor(tree_method=\"hist\", max_depth=6, n_estimators=200),\n",
    "    #\"Gradient Boosting 2\": GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=3, subsample=0.7, min_samples_leaf=5),\n",
    "    \"Random Forest\": RandomForestRegressor( n_estimators=300, max_depth=20, min_samples_leaf=5,max_features='sqrt'),\n",
    "    \"Elastic Net\": ElasticNet(alpha=0.01, l1_ratio=0.5),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=None),\n",
    "    \"Support Vector Regressor\": SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476d58f-61b3-4301-87aa-029d7ee42de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.07625233862552083 Train MSE: 13771.149358131059\n",
      "Test  R2: 0.0744769099326652 Test  MSE: 13822.827023774838\n",
      "7.1768410205841064\n",
      "Ridge Regression\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.07624072915465663 Train MSE: 13771.322431107506\n",
      "Test  R2: 0.07447528579201534 Test  MSE: 13822.85128056055\n",
      "4.315684080123901\n",
      "Lasso Regression\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.0760142678018243 Train MSE: 13774.698497152489\n",
      "Test  R2: 0.07433731776612262 Test  MSE: 13824.911853848447\n",
      "32.15350580215454\n",
      "Gradient Boosting 1\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.19140517711639404 Train MSE: 12054.460625640997\n",
      "Test  R2: 0.07571858167648315 Test  MSE: 13804.280167256717\n",
      "7.858360767364502\n",
      "Random Forest\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.2076305714648583 Train MSE: 11812.574151406514\n",
      "Test  R2: 0.08091350666942831 Test  MSE: 13726.695480144093\n",
      "209.3693928718567\n",
      "Elastic Net\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.07305991160817393 Train MSE: 13818.741780942071\n",
      "Test  R2: 0.07189518606555056 Test  MSE: 13861.385459346317\n",
      "18.611016273498535\n",
      "Decision Tree\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n",
      "Train R2: 0.6191990542903324 Train MSE: 5676.947199284427\n",
      "Test  R2: -0.5030734935847674 Test  MSE: 22448.62946026728\n",
      "19.849617958068848\n",
      "Support Vector Regressor\n",
      "X shape: (351625, 274) y shape: (351625, 1)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "non_na_cols = X_train_final.columns[X_train_final.notna().all()].tolist()\n",
    "\n",
    "for name, model in models.items():\n",
    "    beginning = time()\n",
    "    print(name)\n",
    "    X_fit = X_train_final[non_na_cols]\n",
    "    print(\"X shape:\", X_fit.shape, \"y shape:\", y_train.shape)\n",
    "    if name in [\"Linear Regression\", \"Ridge Regression\", \"Lasso Regression\"]:\n",
    "        model.fit(X_fit, y_train)\n",
    "    else: \n",
    "        model.fit(X_fit, y_train.values.ravel())\n",
    "        #print(\"X shape:\", X_train.shape, \"y shape:\", y_train.shape)\n",
    "        #model.fit(X_train_final, y_train)\n",
    "        #y_pred = model.predict(X_train)\n",
    "    X_train_fit = X_train_final[non_na_cols]\n",
    "    X_test_fit  = X_test_final[non_na_cols]\n",
    "\n",
    "    y_pred_train = model.predict(X_train_fit)\n",
    "    y_pred_test = model.predict(X_test_fit)\n",
    "\n",
    "    # Train metrics\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    # Test metrics\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(\"Train R2:\", r2_train)\n",
    "    print(\"Test  R2:\", r2_test)\n",
    "\n",
    "    results[name] = {\"Train R2\": r2_train,\n",
    "                    \"Test R2\": r2_test}\n",
    "    print(time() - beginning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbd610-1c4a-46a8-a219-d993e791b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ce308-a203-47e6-af35-a80892f9e1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30711dc-5db1-4f03-a1e4-dd4579b0f941",
   "metadata": {},
   "source": [
    "# Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481e27-ef14-4119-a61e-2ef836ae6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = {\n",
    "    \"Linear Regression\": (LinearRegression(), {}),\n",
    "    \"Ridge Regression\": (Ridge(), {\"alpha\": [0.1, 1.0, 10]}),\n",
    "    \"Lasso Regression\": (Lasso(), {\"alpha\": [0.001, 0.01, 0.1]}),\n",
    "    \"Elastic Net\": (ElasticNet(), {\"alpha\": [0.001,0.01,0.1,1],\"l1_ratio\":[0.1,0.5,0.9]}),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestRegressor(),\n",
    "        {\n",
    "            \"n_estimators\":[200,300,500],\n",
    "            \"max_depth\":[10,20,30,None],\n",
    "            \"min_samples_split\":[2,5,10],\n",
    "            \"min_samples_leaf\":[1,2,5],\n",
    "            \"max_features\":[\"sqrt\",\"log2\",0.5]\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBRegressor(tree_method=\"hist\"),\n",
    "        {\n",
    "            \"n_estimators\":[200,400,600],\n",
    "            \"max_depth\":[3,5,7,10],\n",
    "            \"learning_rate\":[0.01,0.05,0.1],\n",
    "            \"subsample\":[0.6,0.8,1.0],\n",
    "            \"colsample_bytree\":[0.6,0.8,1.0],\n",
    "            \"gamma\":[0,1,5]\n",
    "        }\n",
    "    ),\n",
    "    \"Decision Tree\": (\n",
    "        DecisionTreeRegressor(),\n",
    "        {\"max_depth\":[None,10,20,30], \"min_samples_split\":[2,5,10], \"min_samples_leaf\":[1,2,5]}\n",
    "    ),\n",
    "    \"SVR\": (\n",
    "        SVR(),\n",
    "        {\"C\":[0.1,1,10], \"epsilon\":[0.01,0.1,0.5], \"gamma\":[\"scale\",\"auto\"]}\n",
    "    )\n",
    "}\n",
    "\n",
    "non_na_cols = X_train_final.columns[X_train_final.notna().all()].tolist()\n",
    "X_train_fit = X_train_final[non_na_cols]\n",
    "X_test_fit  = X_test_final[non_na_cols]\n",
    "\n",
    "results = {}\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 3️⃣ Loop over models\n",
    "for name, (model, params) in models_params.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    start = time()\n",
    "    \n",
    "    if params:  # if hyperparameters exist, do RandomizedSearchCV\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=params,\n",
    "            n_iter=15,\n",
    "            cv=cv,\n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "        search.fit(X_train_fit, y_train.values.ravel())\n",
    "        best_model = search.best_estimator_\n",
    "        print(\"Best params:\", search.best_params_)\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train_fit, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = best_model.predict(X_train_fit)\n",
    "    y_pred_test  = best_model.predict(X_test_fit)\n",
    "\n",
    "    # Metrics\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    r2_train  = r2_score(y_train, y_pred_train)\n",
    "    mse_test  = mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test   = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Train MSE\": mse_train,\n",
    "        \"Train R2\": r2_train,\n",
    "        \"Test MSE\": mse_test,\n",
    "        \"Test R2\": r2_test\n",
    "    }\n",
    "\n",
    "    print(f\"Train R2: {r2_train:.4f}, Test R2: {r2_test:.4f}, Time: {time()-start:.1f}s\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845c16-6e46-4288-80a3-24ac44f1c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245980f3-3e05-4e44-b460-21bb6ad898df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2ab3d-ab70-48f4-88a4-8b110f1ecf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338d0da-e2c3-4a50-9b57-24185e0c78ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b462b-b490-49ba-bdf4-951480a5031c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9a35d-bcc9-4a82-aaa3-096f282aec51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bc3ba-cff0-4641-98c3-f4d3a3ce3043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16247f-4faa-4a84-a2a4-5a82982da43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bc4f2-c490-45ed-92d6-ba15ea40c004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf27d4-2866-4321-b618-4ecacbc01d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91abbbe-6690-4aa8-af43-b716163ef029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
